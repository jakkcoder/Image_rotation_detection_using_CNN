{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qpnhdSRpNjya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "THIS NOTEBOOK CONTAINS THE PROJECT RAW CODE FOR IMAGE ROATION DETECTION USING IN PRETRAININED MODEL (RESNET)\n",
        "\n",
        "OBJETIVE HERE IS TO GET THE ANGLE OF ROTATION FOR AN IMAGE:\n",
        "\n",
        "\n",
        "Step1. We are generating images with diffrent ratation (0-40) and placing them on raw image at with randaom offset/placement.\n",
        "\n",
        "Step2: We are creating 2 datagenerator for testing and validation\n",
        "\n",
        "Step3: Creating Resnet, training it\n"
      ],
      "metadata": {
        "id": "hdK7ZMEVNmCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# import matplotlib.pyplot as plt\n",
        "from PIL import Image \n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import cv2\n",
        "import os \n",
        "import numpy as np\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input"
      ],
      "metadata": {
        "id": "tVKzz17XETP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"local.jpeg\"\n",
        "\n",
        "src = cv2.imread(file_name, 1)\n",
        "gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
        "th, threshed = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
        "# cv2.imwrite(\"test.png\", dst)\n",
        "cnts = cv2.findContours(threshed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
        "cnt = sorted(cnts, key=cv2.contourArea)[-1]\n",
        "\n",
        "x,y,w,h = cv2.boundingRect(cnt)\n",
        "dst = src[y:y+h, x:x+w]"
      ],
      "metadata": {
        "id": "Y7sHee0VEVcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_,blank_image = cv2.threshold(gray, 255, 255,cv2.THRESH_BINARY_INV)"
      ],
      "metadata": {
        "id": "7715wowtEg0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.fromarray(dst)"
      ],
      "metadata": {
        "id": "NTRM7ga6EjkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Here we are generating the train data of images\n",
        "try:\n",
        "  shutil.rmtree('train_rotation')\n",
        "except:\n",
        "  pass\n",
        "os.mkdir('train_rotation')\n",
        "\n",
        "\n",
        "for i in tqdm(range(0,10)):\n",
        "    img = Image.fromarray(dst)\n",
        "    img = img.rotate(i,expand = 1,fillcolor=255)\n",
        "    img_array = np.array(img)\n",
        "    try:\n",
        "        os.mkdir(f'train_rotation/{i}')\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    for j in range(3000):\n",
        "        l_img = 0\n",
        "        s_img = 0\n",
        "        s_img = img_array[:,:,0].copy()\n",
        "        l_img = blank_image.copy()\n",
        "        x_offset   = np.random.randint(1,100)\n",
        "        y_offset   = np.random.randint(1,100)\n",
        "        l_img[y_offset:y_offset+s_img.shape[0], x_offset:x_offset+s_img.shape[1]] = s_img\n",
        "        im = Image.fromarray(l_img)\n",
        "        im.save(f\"train_rotation/{i}/{j}.png\")"
      ],
      "metadata": {
        "id": "fegY5uccEnzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Here we are generating the test data of images\n",
        "try:\n",
        "  shutil.rmtree('test_rotation')\n",
        "except:\n",
        "  pass\n",
        "os.mkdir('test_rotation')\n",
        "\n",
        "\n",
        "\n",
        "for i in tqdm(range(0,10)):\n",
        "    img = Image.fromarray(dst)\n",
        "    img = img.rotate(i,expand = 1,fillcolor=255)\n",
        "    img_array = np.array(img)\n",
        "    try:\n",
        "        os.mkdir(f'test_rotation/{i}')\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    for j in range(30):\n",
        "        l_img = 0\n",
        "        s_img = 0\n",
        "        s_img = img_array[:,:,0].copy()\n",
        "        l_img = blank_image.copy()\n",
        "        x_offset   = np.random.randint(1,100)\n",
        "        y_offset   = np.random.randint(1,100)\n",
        "        l_img[y_offset:y_offset+s_img.shape[0], x_offset:x_offset+s_img.shape[1]] = s_img\n",
        "        im = Image.fromarray(l_img)\n",
        "        im.save(f\"test_rotation/{i}/{j}.png\")"
      ],
      "metadata": {
        "id": "ODY348kkM_VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_hight,image_width = 224,224\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "GVdmBCEcDteP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "                                   validation_split=.4)"
      ],
      "metadata": {
        "id": "VcVgHsjiGIwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator =train_datagen.flow_from_directory('train_rotation',\n",
        "                                                   target_size =(image_hight,image_width),\n",
        "                                                   batch_size = 32,\n",
        "                                                   class_mode = 'categorical',\n",
        "                                                   subset='training')\n",
        "\n",
        "valid_generator =train_datagen.flow_from_directory('test_rotation',\n",
        "                                                   target_size =(image_hight,image_width),\n",
        "                                                   batch_size = 32,\n",
        "                                                   class_mode = 'categorical',\n",
        "                                                   subset= \"validation\")"
      ],
      "metadata": {
        "id": "MhDo-5MnG1rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers.attention.multi_head_attention import activation\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "base_model = ResNet50(include_top=False,weights='imagenet')\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x= Dense(1024,activation='relu')(x)\n",
        "predictions =Dense(train_generator.num_classes,activation='softmax')(x)\n",
        "model = Model(inputs= base_model.input,outputs=predictions)"
      ],
      "metadata": {
        "id": "oeSLHdfeHWI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "OlJHv3fuIukE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_generator,validation_data=valid_generator,epochs=10)"
      ],
      "metadata": {
        "id": "MxkrgwhfKIqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "563/563 [==============================] - 185s 327ms/step - loss: 0.0622 - accuracy: 0.9854 - val_loss: 0.6028 - val_accuracy: 0.8250\n",
        "<keras.callbacks.History at 0x7f87ea5bf9d0>"
      ],
      "metadata": {
        "id": "m_hV18WUPlxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('final_model.hdf5')"
      ],
      "metadata": {
        "id": "WLK2QzEkbHlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ub_keQS4bYUg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}